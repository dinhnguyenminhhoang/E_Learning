import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration
import json
from tqdm import tqdm
import evaluate
import pandas as pd
from texttable import Texttable
import os
import glob

# ===== C·∫§U H√åNH =====
# Th∆∞ m·ª•c cha ch·ª©a model (Code s·∫Ω t·ª± m√≤ v√†o b√™n trong t√¨m checkpoint m·ªõi nh·∫•t)
BASE_MODEL_DIR = "./t5_large_final_model" 
TEST_FILE = "test_data_jfleg.jsonl"
OUTPUT_CSV = "eval_result.csv"
BATCH_SIZE = 16
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# ====================

def get_latest_checkpoint(base_dir):
    """T√¨m checkpoint c√≥ s·ªë l·ªõn nh·∫•t (M·ªõi nh·∫•t)"""
    if not os.path.exists(base_dir):
        return None
    
    # T√¨m c√°c folder b·∫Øt ƒë·∫ßu b·∫±ng 'checkpoint-'
    checkpoints = glob.glob(os.path.join(base_dir, "checkpoint-*"))
    
    # N·∫øu kh√¥ng c√≥ checkpoint n√†o, th·ª≠ xem c√≥ ph·∫£i model final kh√¥ng
    if not checkpoints:
        if os.path.exists(os.path.join(base_dir, "config.json")):
            return base_dir
        return None
    
    # S·∫Øp x·∫øp theo s·ªë (checkpoint-500 < checkpoint-1000)
    latest_ckpt = max(checkpoints, key=lambda x: int(x.split("-")[-1]))
    return latest_ckpt

def run_evaluation():
    print("üöÄ B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å T·ª™ CHECKPOINT...")
    
    # 1. T√¨m Checkpoint
    model_path = get_latest_checkpoint(BASE_MODEL_DIR)
    if model_path:
        print(f"‚úÖ ƒê√£ t√¨m th·∫•y Checkpoint m·ªõi nh·∫•t: {model_path}")
    else:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y model n√†o trong {BASE_MODEL_DIR}")
        return

    # 2. Load Metrics
    print("‚è≥ ƒêang t·∫£i b·ªô ch·∫•m ƒëi·ªÉm (Metrics)...")
    try:
        metric_bleu = evaluate.load("bleu")
        metric_gleu = evaluate.load("google_bleu")
    except:
        print("‚ùå L·ªói t·∫£i metrics. H√£y ch·∫°y: pip install evaluate sacrebleu")
        return

    # 3. Load Model & Tokenizer
    print("‚è≥ ƒêang t·∫£i Model l√™n GPU...")
    try:
        model = T5ForConditionalGeneration.from_pretrained(model_path).to(DEVICE)
        
        # M·∫∏O: Load Tokenizer g·ªëc ƒë·ªÉ tr√°nh l·ªói thi·∫øu file trong checkpoint
        print("   -> ƒêang load Tokenizer g·ªëc (t5-large)...")
        tokenizer = T5Tokenizer.from_pretrained("t5-large", legacy=False)
        
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return

    model.eval()

    # 4. Load Data Test
    print("‚è≥ ƒêang ƒë·ªçc file Test...")
    inputs = []
    targets = []
    try:
        with open(TEST_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                data = json.loads(line)
                inputs.append(data['input_text'])
                targets.append(data['target_text'])
        print(f"   -> ƒê√£ n·∫°p {len(inputs)} c√¢u test.")
    except:
        print(f"‚ùå Kh√¥ng th·∫•y file {TEST_FILE}")
        return

    # 5. Ch·∫°y d·ª± ƒëo√°n (Inference)
    print("‚öôÔ∏è  ƒêang ch·∫°y s·ª≠a l·ªói (Inference)...")
    predictions = []
    
    # Ch·∫°y batch ƒë·ªÉ nhanh h∆°n
    for i in tqdm(range(0, len(inputs), BATCH_SIZE)):
        batch_src = inputs[i : i+BATCH_SIZE]
        
        encoded = tokenizer(
            batch_src, 
            return_tensors="pt", 
            padding=True, 
            truncation=True, 
            max_length=64
        ).to(DEVICE)
        
        with torch.no_grad():
            outputs = model.generate(
                **encoded, 
                max_length=64, 
                num_beams=2, # Beam search 2 l√† ƒë·ªß nhanh v√† chu·∫©n
                early_stopping=True
            )
        
        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)
        predictions.extend(decoded)

    # 6. T√≠nh ƒëi·ªÉm
    print("üìä ƒêang t√≠nh to√°n ƒëi·ªÉm s·ªë...")
    bleu = metric_bleu.compute(predictions=predictions, references=targets)
    gleu = metric_gleu.compute(predictions=predictions, references=targets)
    
    # T√≠nh Exact Match (T·ª∑ l·ªá ƒë√∫ng tuy·ªát ƒë·ªëi)
    exact_matches = 0
    for p, t in zip(predictions, targets):
        # Chu·∫©n h√≥a nh·∫π tr∆∞·ªõc khi so s√°nh (b·ªè kho·∫£ng tr·∫Øng th·ª´a)
        if p.strip() == t.strip():
            exact_matches += 1
            
    exact_score = (exact_matches / len(targets)) * 100

    # 7. In B√°o C√°o
    t = Texttable()
    t.add_rows([
        ["CH·ªà S·ªê (METRIC)", "ƒêI·ªÇM S·ªê", "√ù NGHƒ®A"],
        ["BLEU", f"{bleu['bleu']:.4f}", "ƒê·ªô t∆∞∆°ng ƒë·ªìng t·ª´ ng·ªØ (C√†ng cao c√†ng t·ªët)"],
        ["GLEU (Google)", f"{gleu['google_bleu']:.4f}", "ƒê·ªô tr√¥i ch·∫£y & ch·ªânh s·ª≠a (Quan tr·ªçng)"],
        ["EXACT MATCH", f"{exact_score:.2f}%", "T·ª∑ l·ªá s·ª≠a ƒë√∫ng ho√†n to√†n 100%"]
    ])
    print("\n" + t.draw())

    # 8. L∆∞u file Excel ƒë·ªÉ soi
    df = pd.DataFrame({
        "Input (Sai)": [s.replace("grammar: ", "") for s in inputs],
        "Target (Chu·∫©n)": targets,
        "Model S·ª≠a": predictions,
        "ƒê√∫ng tuy·ªát ƒë·ªëi?": [p.strip() == t.strip() for p, t in zip(predictions, targets)]
    })
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ chi ti·∫øt v√†o: {OUTPUT_CSV}")

if __name__ == "__main__":
    run_evaluation()